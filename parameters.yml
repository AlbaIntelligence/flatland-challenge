# Environment cofiguration
env:
  # Random seed used to generate rails
  seed: 14
  # Number of trains to spawn
  num_trains: 3
  # Environment width
  width: 48
  # Environment height
  height: 27
  # Maximum number of moves in an episode
  max_moves: 500
  # Maximum number of cities where agents can start or end
  max_cities: 5
  # Type of city distribution
  grid: False
  # Maximum number of tracks allowed between cities
  max_rails_between_cities: 2
  # Maximum number of parallel tracks within a city
  max_rails_in_cities: 3
  # Enable variable speed
  variable_speed: False
  # Malfunctions config
  malfunctions:
    # Enable malfunctions
    enabled: False
    # Malfunction rate
    rate: !!float 1e-4
    # Malfunction minimum duration
    min_duration: 15
    # Malfunction maximum duration
    max_duration: 50

# Observator config
observator:
  # Maximum depth for the observator
  max_depth: 5

# Predictor config
predictor:
  # Maximum depth for the predictor
  max_depth: 5

# Policy config
policy:
  # Select policy type
  type:
    # GNN observation policy
    graph: False
    # Standard tree observation policy
    tree: False
    # Binary tree observation policy
    binary_tree: True
    # Random policy
    random: False

# Action selector config
action_selector:
  # Type of action selector
  type:
    # Epsilon-greedy action selection
    eps_greedy: True
    # Boltzmann action selection
    boltzmann: False
    # Random action selection
    random: False
    # Greedy action selection
    greedy: False
    # Categorical action selection
    categorical: False

# Action selection parameter decay config
parameter_decay:
  # Type of decay
  type:
    # Linear decay (param - decay)
    linear: True
    # Exponential decay (param * decay)
    exponential: False
    # No decay
    none: False
  # Initial exploration
  start: !!float 1.0
  # Final exploration
  end: !!float 0.01
  # Percentage of episode with parameter greater than final exploration
  decaying_episodes: !!float 0.70

# Learning config
learning:
  # Learning rate
  learning_rate: !!float 0.5e-4
  # Weight multiplier for target network soft update
  tau: !!float 1e-3
  # Discount multiplier for expected Q-value of targets
  discount: !!float 0.99
  # Bellman fuction
  softmax_bellman: False
  # Loss function
  loss:
    # Huber loss
    huber: True
    # MSE loss
    mse: False
  # Type of gradient clipping
  gradient:
    # Maximum value for the norm of the gradients
    max_norm: 10
    # Maximum symmetrical limit for the values of the gradients
    value_limit: 1
    # Clip the norm of the gradients (`max_grad_norm`)
    clip_norm: True
    # Clamp the gradient itself (-`grad_value_limit`, `grad_value_limit`)
    clamp_values: False

# Model config
model:
  # Enable or disable dueling DQN
  dueling: True
  # Enable or disable double DQN
  double: True
  # The number of hidden layer with their hidden sizes
  hidden_sizes:
    - 128
    - 128
  # Non-linear function
  nonlinearity:
    # ReLU function
    relu: True
    # Tanh function
    tanh: False
  # GNN configuration
  gnn:
    # Size of the hidden layers
    hidden_size: 8
    # Size of the output embedding
    embedding_size: 4
    # Number of embeddings to pass to the DQN
    pos_size: 3
    # Dropout value
    dropout: !!float 0.0
    # Aggregation function
    aggr_function:
      # Mean function
      mean: False
      # Sum function
      sum: True

# Replay buffer config
replay_buffer:
  # Maximum buffer dimension
  size: 100000
  # Batch size
  batch_size: 128
  # Try to learn after this many steps
  checkpoint: 4
  # Replay buffer to restore
  load: ""
  # Save replay buffer at each checkpoint
  save: False

# Generic config
generic:
  # Number of threads PyTorch can use
  num_threads: 1
  # Fix all the possible sources of randomness
  fix_random: True
  # Random seed used when `fix_random` is True
  random_seed: 1
  # Device config
  use_gpu: False
  # Enable wandb logging
  enable_wandb: True
  # Checkpoint to save model to wandb
  wandb_checkpoint: 500
  # Gradients logging in wandb
  wandb_gradients:
    # Enable or disable logging
    enabled: False
    # How often to log gradients
    checkpoint: 200

# Training config
training:
  # Checkpoint interval (how often to evaluate and save the model)
  checkpoint: 200

  # Train enviroment config
  train_env:
    # Path to the train environment file
    load: ""
    # Number of training episodes to run
    episodes: 2500
    # Train on random enviroments or on the same one
    all_random: False

  # Evaluation enviroment config
  eval_env:
    # Path to the evaluation environment file
    load: ""
    # Number of evaluation episodes
    episodes: 25
    # Evaluate on random enviroments or on the same one
    all_random: False

  # Renderer config
  renderer:
    # Render episodes during training
    training: True
    # How often to render an episode in training
    train_checkpoint: 150
    # Render episodes during evaluation
    evaluation: True
    # How often to render an episode in evaluation
    eval_checkpoint: 10

testing:
  # Path to the environment file
  load: ""
  # Path to the model to load
  model: "x"
  # Seconds to sleep between moves
  sleep: 0
  # Save intermediate renderer frames
  save_frames: True
